{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# План\n",
    "\n",
    "* ✔ Разобраться с итоговыми графиками, быть уверенным что там все правильно. (19-21)\n",
    "\n",
    "\n",
    "1. ~~Проверить рассматриваемые функционалы на простых графах, где ее можно посчитать, проверить что смешанная модулярность равна обычной, если группы вершин не будут пересекаться.~~\n",
    "* ~~Проверить, что проводимость учитывает взвешенность.~~\n",
    "* ~~Проанализировать NMF --- почему выдает высокое качество, там где оно высокое и т.д. Закрыть вопросы по нему (Посмотреть на критерий выделения сообществ из матрицы и истинное количество сообществ, которое выдает метод (часть пустая --- низкая проводимость?).~~\n",
    "* ✔ Добаввить значения истинного разбиения на графики для большей наглядности.\n",
    "* ✔ Добавить CFinder для сравнения с ним.\n",
    "* ✔ Добавить State of the art метод для выделения непересекающихся сообществ\n",
    "* Провести эксперименты для больших графов.\n",
    "\n",
    "\n",
    "* ✔ Провести полноценные эксперименты с инициализацией на бенчмарке. (22)\n",
    "* Оформить все в текст, т.е. переделать и дополнить текст курсовой в статью. (22-25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import igraph as ig\n",
    "import scipy as sp\n",
    "import scipy.spatial as spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import cPickle\n",
    "from Extends import *\n",
    "import subprocess\n",
    "import os\n",
    "from big_clam import BigClam\n",
    "from big_clam_gamma import BigClamGamma\n",
    "from Experiments import *\n",
    "from time import gmtime, strftime\n",
    "from collections import defaultdict\n",
    "from cPickle import dump, load\n",
    "from shutil import copyfile\n",
    "def time():\n",
    "    return strftime(\"%H:%M:%S \", gmtime())\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "def NMF_clust(A, K):\n",
    "    model = NMF(n_components=K)\n",
    "    res = model.fit_transform(A)\n",
    "    #print res.shape\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_graph(G, comms, size=12, bord=1.5):\n",
    "    ax = plt.figure(figsize=(size, size))\n",
    "    #nx.draw_networkx(G_test, pos=pos, node_size=25, alpha=0.3, linewidths=0, width=0.5, with_labels=False)\n",
    "    max_w = max(e[2]['weight'] for e in G.edges(data=True))\n",
    "\n",
    "    node_size = 2 * size\n",
    "    drawn = []\n",
    "    print '1'\n",
    "    for col_i, i in enumerate(comms):\n",
    "        print '.',\n",
    "        G_part = nx.subgraph(G, comms[i])\n",
    "        width = [2 * e[2]['weight'] / max_w for e in G_part.edges(data=True)]\n",
    "        edgelist = list(G_part.edges())\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=edgelist, width=width, alpha=0.15, edge_color=col[col_i if col_i < len(col) else -1])\n",
    "        drawn.extend(edgelist)\n",
    "    print '2'\n",
    "    temp = list(set(G.edges())- set(drawn))\n",
    "    print '2.5'\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=temp , width=width, alpha=0.15)\n",
    "    print '3'\n",
    "    nx.draw_networkx_nodes(G, pos, node_color='#FFFFFF', node_size=node_size, alpha=1, linewidths=0)\n",
    "    if len(comms) > len(col):\n",
    "        print 'WARNING: too low colors count'\n",
    "    print '4'\n",
    "    for j in G:\n",
    "        #print '.',\n",
    "        node_cols = [(col_i if col_i < len(col) else col_i%len(col)) for col_i, i in enumerate(comms) if j in comms[i]]\n",
    "        for k, col_i in enumerate(node_cols):\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=[j], node_color=col[col_i], node_size=(len(node_cols)-k) * node_size,\n",
    "                                   alpha=1, linewidths=0, width=0.3, with_labels=False)\n",
    "            #nx.draw_networkx_labels(G,pos)\n",
    "    \n",
    "    plt.xlim([-bord, bord])\n",
    "    plt.ylim([-bord, bord])\n",
    "    plt.axis('off')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_all=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def enshure_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "lanc_bech_files = ['outputlog', 'parameters.dat', 'community.dat', 'statistics.dat', 'time_seed.dat', 'network.dat']\n",
    "nmi_files = ['outputlog-nmi', 'clu1', 'clu2']\n",
    "model_files = {'COPRA': ['../external/COPRA/COPRA_output.log', '../external/COPRA/test.COPRA', 'clusters-test.COPRA'],\n",
    "               'BigClam-orig-zeros': ['../external/BigClam/bigClam_output.log', '../external/BigClam/test.bigClam', '../external/BigClam/cmtyvv.txt' ]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def worker(iter, mix):\n",
    "        res = {name: {key: 0 for key in qual_fun} for name in models}\n",
    "        print ' {}:'.format(iter),\n",
    "        G, comms = LancichinettiBenchmark(**data_params)\n",
    "        if save_all:\n",
    "            cur_save_dir = \"../data/dumps/all_exp/{:.3f}/\".format(mix)\n",
    "            enshure_dir(cur_save_dir)\n",
    "            cur_save_dir = cur_save_dir + str(iter) + '/'\n",
    "            enshure_dir(cur_save_dir)\n",
    "            for filename in lanc_bech_files:\n",
    "                copyfile('../external/Lancichinetti benchmark/' + filename, cur_save_dir + 'testgraph-' + filename)\n",
    "        A = np.zeros(shape=(len(G), len(G)))\n",
    "        for u, v, data in G.edges(data=True):\n",
    "            A[int(u)-1][int(v)-1] = data['weight']\n",
    "        #Fs = pool.map(worker_models, zip([A]*len(models), [comms]*len(models), models.keys()))\n",
    "        Fs = [worker_models((A, comms, name)) for name in models]\n",
    "\n",
    "        Fs = dict(Fs)\n",
    "        for name in Fs:\n",
    "            for key in qual_fun:\n",
    "                try:\n",
    "                    if key not in {\"1-NMI\", \"NMI\", 'NMI_new'}:\n",
    "                        q = qual_fun[key](Fs[name], A)\n",
    "                    else:\n",
    "                        q = qual_fun[key](Fs[name], A, comms)\n",
    "                        if save_all:\n",
    "                            for filename in nmi_files:\n",
    "                                copyfile('../external/Lancichinetti benchmark/' + filename, cur_save_dir + name + '-' + filename)\n",
    "                except:\n",
    "                    print 'Some err in ' + name,\n",
    "                    q = float('nan')\n",
    "                res[name][key] = q\n",
    "            if save_all:\n",
    "                with file(cur_save_dir + name + '-' 'quals', 'w') as f:\n",
    "                    for key in res[name]:\n",
    "                        f.write('{}: {}\\n'.format(key, res[name][key]))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def worker_models(args):\n",
    "    A, comms, name = args\n",
    "    print name,\n",
    "    if name != 'groundtruth':\n",
    "        F = models[name](A, len(comms), name)\n",
    "    else:\n",
    "        F = models[name](comms)\n",
    "    print '.',\n",
    "    return name, F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean(l):\n",
    "    #lt = [x for x in l if 1 > x ]\n",
    "    lt = l\n",
    "    return 1.0 * sum(lt) / len(lt) if len(lt) > 0 else float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'initF': 'cond_randz',\n",
    "    'LLH_output': False,\n",
    "    'iter_output': 20000,\n",
    "    'processesNo': 1,\n",
    "    'dump': False,\n",
    "    'eps': 1e-3,\n",
    "    \"max_iter\": 500000,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = {'BigClam-Zeros': lambda A, K, name: BigClam(1.0 * (A != 0), K, dump_name=name, **model_params).fit()[0],\n",
    "          #'BigClam-Zeros-simple': lambda A, K, name: BigClam(1.0 * (A != 0), K, dump_name=name, stepSizeMod='simple', **model_params).fit()[0],\n",
    "          #'BigClam-Mean': lambda A, K, name: BigClam(1.0 * (A < np.mean(A)), K, dump_name=name, **model_params).fit()[0],\n",
    "          #'BigClamWeighted': lambda A, K, name: BigClam(A, K, dump_name=name, **model_params).fit()[0],\n",
    "          #'BigClamWeighted-simple': lambda A, K, name: BigClam(A, K, dump_name=name, stepSizeMod='simple', **model_params).fit()[0],\n",
    "          #'SparseGamma-p1': lambda A, K, name: BigClamGamma(A, K, dump_name=name, pow=1, **model_params).fit()[0],\n",
    "          #'SparseGamma-p0.05': lambda A, K, name: BigClamGamma(A, K, dump_name=name, pow=0.05, **model_params).fit()[0],\n",
    "          #'SparseGamma': lambda A, K, name: BigClamGamma(A, K, dump_name=name, **model_params).fit()[0],\n",
    "          'BigClam-orig-zeros': lambda A, K, name: bigclam_orig(1.0 * (A != 0), K),\n",
    "          #'BigClamWeighted-sp10': lambda A, K, name: BigClam(A, K, dump_name=name, sparsity_coef=10,  **model_params).fit()[0],\n",
    "          #'SparseGamma-sp10': lambda A, K, name: BigClamGamma(A, K, dump_name=name, sparsity_coef=10, **model_params).fit()[0],\n",
    "          #'BigClam-orig-mean': lambda A, K, name: bigclam_orig(1.0 * (A < np.mean(A)), K),\n",
    "          #'COPRA': lambda A, K, name: copra(A, K),\n",
    "          #'NMF': lambda A, K, name: NMF_clust(A, K),\n",
    "          'groundtruth': lambda res: [map(int, res[key]) for key in res],\n",
    "          #'CFinder': lambda A, K, name: CFinder(A, K),\n",
    "          #'CPM': lambda A, K, name: [list(x) for x in get_percolated_cliques(nx.from_numpy_matrix(1.0 * (A != 0)), 5)]\n",
    "          'walktrap': lambda A, K, name: walktrap(A, K),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score as mi\n",
    "\n",
    "qual_fun = OrderedDict([\n",
    "            ('1-MeanConductance', lambda F, A: 1-MeanConductance(GetComms(F, A), A) if not isinstance(F, list) else 1-MeanConductance(F, A)),\n",
    "            ('1-MaxConductance', lambda F, A: 1-MaxConductance(GetComms(F, A), A) if not isinstance(F, list) else 1-MaxConductance(F, A)),\n",
    "            ('NMI', lambda F,A, true_comm: NMI(GetComms(F, A), A, true_comm) if not isinstance(F, list) else NMI(F, A, true_comm)),\n",
    "            #('NMI_new', lambda F,A, true_comm: NMI3(GetComms(F, A), A, true_comm) if not isinstance(F, list) else NMI(F, A, true_comm)),\n",
    "            ('MixedModularity', MixedModularity),\n",
    "            #('NMI_skl', lambda F,A, true_comm: normalized_mutual_info_score(GetComms(F, A)))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calc_res(data_params, save_path='../data/dumps/models_res_full-dump'):\n",
    "    iter_count = 1\n",
    "    if save_all:\n",
    "        enshure_dir(\"../data/dumps/all_exp\")\n",
    "    mixing_range = np.linspace(0, 0.5, 6)\n",
    "    #mixing_range = np.linspace(0, 0.5, 3)\n",
    "    models_res = []\n",
    "    for i_mix, mix in enumerate(mixing_range):\n",
    "        print '{} mix: {}'.format(time(), mix)\n",
    "        with file(r'..\\external\\Lancichinetti benchmark\\time_seed.dat', 'w') as f:\n",
    "            f.write(str(seed))\n",
    "        data_params['on'] = np.floor(data_params['N'] * mix)\n",
    "        one_graph_res = {name: OrderedDict([(key, []) for key in qual_fun]) for name in models}\n",
    "        res = []\n",
    "        for iter in xrange(iter_count):\n",
    "            res.append(worker(iter, mix))\n",
    "        #res = pool.map(worker, xrange(iter_count))\n",
    "        for iter in xrange(iter_count):\n",
    "            for name in one_graph_res:\n",
    "                for key in one_graph_res[name]:\n",
    "                    one_graph_res[name][key].append(res[iter][name][key])\n",
    "\n",
    "        models_res.append(one_graph_res)\n",
    "        dump((models_res, mixing_range, mix, data_params),\n",
    "             file(save_path + '-part-{}'.format(i_mix), 'w'))\n",
    "\n",
    "    dump((models_res, mixing_range, mix, data_params), file(save_path, 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_res(res_path='../data/dumps/models_res_full-dump'):\n",
    "    (models_res, mixing_range, mix, data_params) = load(file(res_path))\n",
    "\n",
    "    models_ = models_res[0].keys()\n",
    "    qual_fun_ = models_res[0][models_[0]].keys()\n",
    "    print models_, qual_fun_\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    #plt.figure(figsize=(14, 40))\n",
    "    for indx, qual_name in enumerate(qual_fun_):\n",
    "        plt.subplot(2, len(qual_fun_) / 2, indx + 1)\n",
    "        #plt.subplot(len(qual_fun_), 2, indx + 1)\n",
    "        plt.ylabel('{}, N={}'.format(qual_name, data_params['N']))\n",
    "        plt.xlabel('mixing parameter')\n",
    "        colors = plt.get_cmap('hsv')(np.linspace(0, 1.0, len(models_) + 1))\n",
    "        for i, name in enumerate(models_):\n",
    "            #if name in ['SparseGamma-p1', 'BigClamWeighted-simple', 'BigClam-Zeros-simple', 'BigClam-Zeros', 'SparseGamma-p0.05']:\n",
    "            #    continue\n",
    "            plt.plot(mixing_range, [mean(res[name][qual_name]) for res in models_res if len(res) != 0], label=name,\n",
    "                     color=colors[i] if name != 'groundtruth' else 'k', marker=('.', 'o', 'x', '+')[i%4])\n",
    "        if indx == 1:\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        #plt.ylim([-0.05, 1.05])\n",
    "    plt.show()\n",
    "    plt.savefig('../plots/{}_{}.eps'.format(data_params['N'], data_params['mut']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 21113222\n",
    "data_params = {\n",
    "    'N': None,\n",
    "     'mut': None,\n",
    "     'maxk': 50,\n",
    "     'k': 30,\n",
    "     'om': 2,\n",
    "     'muw': None,\n",
    "     'beta': 2,\n",
    "     't1': 2,\n",
    "     't2': 2,\n",
    "     'on': 0,\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ~~~~~~~~~~~~~~ 1000 0.1 0.1 ~~~~~~~~~~~~~~\n",
      "08:51:56  mix: 0.0\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 08:53:27  mix: 0.1\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 08:55:15  mix: 0.2\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 08:56:56  mix: 0.3\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 08:58:39  mix: 0.4\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 09:00:25  mix: 0.5\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . ~~~~~~~~~~~~~~ 1000 0.3 0.3 ~~~~~~~~~~~~~~\n",
      "09:02:22  mix: 0.0\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 09:04:35  mix: 0.1\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 09:06:51  mix: 0.2\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 09:09:16  mix: 0.3\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 09:11:56  mix: 0.4\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 09:15:10  mix: 0.5\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . ~~~~~~~~~~~~~~ 5000 0.1 0.1 ~~~~~~~~~~~~~~\n",
      "09:19:23  mix: 0.0\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 10:08:01  mix: 0.1\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 11:01:50  mix: 0.2\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 11:56:06  mix: 0.3\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 12:51:51  mix: 0.4\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 13:53:41  mix: 0.5\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . ~~~~~~~~~~~~~~ 5000 0.3 0.3 ~~~~~~~~~~~~~~\n",
      "14:56:46  mix: 0.0\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 15:40:05  mix: 0.1\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 16:27:07  mix: 0.2\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 17:15:30  mix: 0.3\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 18:00:42  mix: 0.4\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA . 18:52:51  mix: 0.5\n",
      " 0: SparseGamma . BigClamWeighted . walktrap . NMF . BigClam-orig-zeros . groundtruth . COPRA .\n"
     ]
    }
   ],
   "source": [
    "data_params['N'] = 1000\n",
    "data_params['mut'] = 0.1\n",
    "data_params['muw'] = 0.1\n",
    "print '~~~~~~~~~~~~~~ {} {} {} ~~~~~~~~~~~~~~'.format(data_params['N'], data_params['mut'], data_params['muw'])\n",
    "calc_res(data_params, '../data/dumps/models_res_full-dump-{}-{}'.format(data_params['N'], data_params['mut']))\n",
    "\n",
    "data_params['mut'] = 0.3\n",
    "data_params['muw'] = 0.3\n",
    "print '~~~~~~~~~~~~~~ {} {} {} ~~~~~~~~~~~~~~'.format(data_params['N'], data_params['mut'], data_params['muw'])\n",
    "calc_res(data_params, '../data/dumps/models_res_full-dump-{}-{}'.format(data_params['N'], data_params['mut']))\n",
    "\n",
    "data_params['N'] = 5000\n",
    "data_params['mut'] = 0.1\n",
    "data_params['muw'] = 0.1\n",
    "print '~~~~~~~~~~~~~~ {} {} {} ~~~~~~~~~~~~~~'.format(data_params['N'], data_params['mut'], data_params['muw'])\n",
    "calc_res(data_params, '../data/dumps/models_res_full-dump-{}-{}'.format(data_params['N'], data_params['mut']))\n",
    "\n",
    "data_params['mut'] = 0.3\n",
    "data_params['muw'] = 0.3\n",
    "print '~~~~~~~~~~~~~~ {} {} {} ~~~~~~~~~~~~~~'.format(data_params['N'], data_params['mut'], data_params['muw'])\n",
    "calc_res(data_params, '../data/dumps/models_res_full-dump-{}-{}'.format(data_params['N'], data_params['mut']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print\n",
    "print\n",
    "for mix, res in zip(mixing_range, models_res):\n",
    "    for key in res:\n",
    "        print mix, ': ', key, res[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
